{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input/facial-expression/fer2013/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 48\nCLIPED_SIZE = 42\nEMO_NUM = 7\nBATCH_SIZE = 50\nNUM_CHANNEL = 1\nEPOCHS = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the data\nfilname = '../input/facial-expression/fer2013/fer2013.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames = ['emotion', 'pixels', 'usage']\ndf = pd.read_csv('../input/facial-expression/fer2013/fer2013.csv', names=names, na_filter=False)\nim = df['pixels']\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) / 255.0, np.array(Y)\n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y = getData(filname)\nnum_class = len(set(Y))\nprint(num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keras with tensorflow backend\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 进行左右对称\ndef GetSymmetric(pixel, size):\n    '''\n    pixel: np array with shape (count,size,size,1)\n    '''\n    count = pixel.shape[0]\n    sym = np.zeros((count, size, size, NUM_CHANNEL))\n    for i in range(count):\n        for j in range(size):\n            for k in range(size):\n                sym[i,j,k,0] = pixel[i,j,size-k-1,0]\n    return sym","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symmetric_x_train = GetSymmetric(X_train, IMAGE_SIZE)\nX_train = np.concatenate((X_train, symmetric_x_train), axis = 0)\ny_train = np.concatenate((y_train, y_train))\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\n# Cliped\ndef GetClipedImage(pixel, start):\n    '''\n    pixel: raw 48*48 pixel data with shape (count, 48, 48, 1)\n    start: a tuple such as (0,0),(2,3),(4,2), represents start point of clipped 42*42 image\n    '''\n    count = pixel.shape[0]\n    out = np.zeros((count, CLIPED_SIZE, CLIPED_SIZE, NUM_CHANNEL))\n    for i in range(count):\n        for j in range(CLIPED_SIZE):\n            out[i,j,:,0] = pixel[i,start[0]+j,start[1]:start[1]+CLIPED_SIZE,0]\n    return out\n# To process\ndef DataPreprocess(pixel, label = []):\n    '''\n    pixel: pixel data with shape (count,48,48,1)\n    label: optical, corresponding label of pixel\n    '''\n    a = random.randint(0,2)\n    b = random.randint(3,5)\n    c = random.randint(0,2)\n    d = random.randint(3,5)\n    pixel1 = GetClipedImage(pixel, (a,c))\n    pixel2 = GetClipedImage(pixel, (a,d))\n    pixel3 = GetClipedImage(pixel, (b,c))\n    pixel4 = GetClipedImage(pixel, (b,d))\n    out_p = np.concatenate((pixel1, pixel2, pixel3, pixel4), axis = 0)\n    if len(label) == 0:\n        return out_p\n    else:\n        out_l = np.concatenate((label, label, label, label), axis = 0)\n        return (out_p, out_l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, y_train) = DataPreprocess(X_train, y_train)\n(X_test, y_test) = DataPreprocess(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 数据sao操作\ndatagen = ImageDataGenerator(\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    \n    input_shape = (42, 42, 1)\n    \n    model=Sequential()\n    model.add(Conv2D(32,(1,1),strides=1,padding='same',input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(Conv2D(32,(5,5),padding='same'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    \n    model.add(Conv2D(32,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n \n    model.add(Conv2D(64,(5,5),padding='same'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n        \n    model.add(Flatten())\n    model.add(Dense(2048))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1024))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    model.summary()\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\npath_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n# model=my_model() # create the model\n\nmodel = my_model()\n\n# K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n\nmodel.compile(optimizer=adam(lr=1e-3), loss=\"mae\")\n\n# fit the model\nh=model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n                    epochs=50,\n                    verbose=1,\n                    validation_data=(X_test,y_test),\n                    callbacks=[\n                        ModelCheckpoint(filepath=path_model),\n                    ]\n                   )\n\n# h=model.fit(x=X_train,     \n#             y=y_train, \n#             batch_size=64, \n#             epochs=20, \n#             verbose=1, \n#             validation_data=(X_test,y_test),\n#             shuffle=True,\n#             callbacks=[\n#                 ModelCheckpoint(filepath=path_model),\n#             ]\n#             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def emotion_analysis(emotions):\n#     objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n#     y_pos = np.arange(len(objects))\n#     plt.bar(y_pos, emotions, align='center', alpha=0.9)\n#     plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n#     plt.xticks(y_pos, objects)\n#     plt.ylabel('percentage')\n#     plt.title('emotion')\n    \n# plt.show()\n\ndef emotion_analysis(emotions):\n    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n    y_pos = np.arange(len(objects))\n \n    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(X_test)\n# print(y_pred)\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import seaborn as sn\n#import pandas as pd\n#import matplotlib.pyplot as plt\n#import numpy as np\n#from sklearn.metrics import confusion_matrix\n#%matplotlib inline\n#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n                  #columns = [i for i in \"0123456\"])\n#plt.figure(figsize = (20,15))\n#sn.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/testimages/myself.jpg', grayscale=True, target_size=(42, 42))\nshow_img=image.load_img('../input/testimages/myself.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\nprint(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([42, 42])\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}