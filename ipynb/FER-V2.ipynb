{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"},"cell_type":"code","source":"# get the data\nfilname = '../input/facial-expression/fer2013/fer2013.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\ndf=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfde4d91ff367dfa6764202c1b309ea291fb833a"},"cell_type":"code","source":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) / 255.0, np.array(Y)\n    return X, Y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"435d0e06553e3de3fd982e4a4a86c28018ac3913"},"cell_type":"code","source":"X, Y = getData(filname)\nnum_class = len(set(Y))\nprint(num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e"},"cell_type":"code","source":"# keras with tensorflow backend\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be4faef86c3c5635697f10939547edd5c8760308"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3afd36886a65ff49fe48ac73271f7477b574375a"},"cell_type":"code","source":"from keras.layers import Activation, Convolution2D, Dropout, Conv2D\nfrom keras.layers import AveragePooling2D, BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import SeparableConv2D\nfrom keras import layers\nfrom keras.regularizers import l2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (48, 48, 1)\nnum_classes = 7\n# lr = 1e-3\nbatch_size = 32\nepochs = 10000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8eaecce539d06c983ed73142ac1484dbfa5e970"},"cell_type":"code","source":"def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n    regularization = l2(l2_regularization)\n\n    # base\n    img_input = Input(input_shape)\n    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n                                            use_bias=False)(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n                                            use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # module 1\n    residual = Conv2D(16, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(16, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(16, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 2\n    residual = Conv2D(32, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(32, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(32, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 3\n    residual = Conv2D(64, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(64, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(64, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 4\n    residual = Conv2D(128, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(128, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(128, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    x = Conv2D(num_classes, (3, 3),\n            #kernel_regularizer=regularization,\n            padding='same')(x)\n    x = GlobalAveragePooling2D()(x)\n    output = Activation('softmax',name='predictions')(x)\n\n    model = Model(img_input, output)\n    return model\n\nmodel=mini_XCEPTION(input_shape, num_classes)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5004be413385dbdf6c3967d34c59e541095ea667"},"cell_type":"code","source":"from keras import backend as K\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint\n\npath_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n\nmodel=mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01) # create the model\n\nmodel.compile(optimizer='adam', # 优化器采用adam\n              loss='categorical_crossentropy', # 多分类的对数损失函数\n              metrics=['accuracy'])\n\n# fit the model\nh=model.fit_generator(data_generator.flow(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=X_train.shape[0],\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(X_test,y_test),\n                    callbacks=[\n                        ModelCheckpoint(filepath=path_model),\n                    ]\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c7e2abb2a89f4df0d28de0a49db1f60c84fbcf0"},"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"077d44e8bbb7549a09682eb09c417903bf2fd935"},"cell_type":"code","source":"def emotion_analysis(emotions):\n    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"241291244491cc1e84a45ecb0da66c1c09a4cd7a"},"cell_type":"code","source":"y_pred=model.predict(X_test)\n#print(y_pred)\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e97d2cb00640d2bfc4d4de9456249e893f72cc2"},"cell_type":"code","source":"#import seaborn as sn\n#import pandas as pd\n#import matplotlib.pyplot as plt\n#import numpy as np\n#from sklearn.metrics import confusion_matrix\n#%matplotlib inline\n#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n                  #columns = [i for i in \"0123456\"])\n#plt.figure(figsize = (20,15))\n#sn.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Real Time Expression Prediction**","execution_count":null},{"metadata":{"trusted":true,"_uuid":"70fc48e66d18c54ba629e625ad8def5ad2d93fa6"},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/myimage/Shawon.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('../input/myimage/Shawon.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82db72b60f80eb18474bf880369791cf346c9749"},"cell_type":"code","source":"from skimage import io\nimg = image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx /= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Live Demo of Production Level Project**\n\n[Facial Expression Detection Web App](https://faceai.herokuapp.com/)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}